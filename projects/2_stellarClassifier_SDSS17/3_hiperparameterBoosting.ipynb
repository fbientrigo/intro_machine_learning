{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "classes = [0,1,2]\n",
    "classes_names = ['GALAXY','STAR','QSO']\n",
    "\n",
    "y_train = df_train[\"class\"].values\n",
    "X_train = df_train.drop([\"class\"], axis=1).values\n",
    "\n",
    "# Preparar los datos del training\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "del(X_train)\n",
    "\n",
    "# GridSearch automaticamente va a dividir en trainig/validation internamente\n",
    "# usando una estrategia llamada K-Folds\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size = 0.33, random_state = 42)\n",
    "\n",
    "X_train = X_train_scaled\n",
    "\n",
    "y_test = df_test[\"class\"].values\n",
    "X_test = df_test.drop([\"class\"], axis=1).values\n",
    "\n",
    "# liberar de memoria\n",
    "del(df_train)\n",
    "del(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algo util es poder desordenar los datos\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle X_train and y_train together\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes\n",
      "X_train (121422, 9)\n",
      "y_train (121422,)\n",
      "X_val (16949, 9)\n",
      "y_val (16949,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shapes\")\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "print(\"X_val\", X_test.shape)\n",
    "print(\"y_val\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como seleccionar Hiperparametros\n",
    "Esta es la parte que requiere mayor poder de computo, estan las ideas de hiperparametros que son cantidades que decidimos al construir los modelos, en el caso de los arboles de decisión es la cantidad de nodos maximos\n",
    "\n",
    "Existen varios metodos para seleccionarlos, en este caso enseñaré el metodo más facil de entender y que solo requiere un montón de computo.\n",
    "- Grid Search\n",
    "\n",
    "Pueds probar alternativas más sofisticadas como\n",
    "- Bayesian Hyperparameter Tunning; que he utilizado para entrenar redes neuronales y encontrar las versiones más eficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases en y_train: [0 1 2]\n",
      "Número de clases en y_val: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Verifica el número de clases en el conjunto de entrenamiento\n",
    "print(\"Número de clases en y_train:\", np.unique(y_train[:100]))\n",
    "\n",
    "# Verifica el número de clases en el conjunto de validación\n",
    "print(\"Número de clases en y_val:\", np.unique(y_test[:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Halving Grid Search es experimental, asi que requiere importar esto extra\n",
    "# from sklearn.experimental import enable_halving_search_cv \n",
    "# from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el clasificador base\n",
    "base_clf = RandomForestClassifier()\n",
    "\n",
    "# Definir el clasificador de AdaBoost\n",
    "boosted_clf = AdaBoostClassifier(estimator=base_clf, algorithm=\"SAMME\")\n",
    "\n",
    "# Definir los hiperparámetros que queremos ajustar\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 50, 100, 200],  # Número de árboles en el clasificador base (Random Forest)\n",
    "    'n_estimators': [50, 100, 150, 200],  # Número de iteraciones de AdaBoost\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1.0],  # Tasa de aprendizaje de AdaBoost\n",
    "    'estimator__max_depth': [5, 10, 20],  # Profundidad máxima del Random Forest\n",
    "    'estimator__min_samples_split': [2, 5, 10, 50]  # Mínimo de muestras por nodo para dividir\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para ajustar los hiperparámetros con barra de progreso\n",
    "# grid_search = HalvingGridSearchCV(boosted_clf, param_grid, scoring='accuracy', cv=3, n_jobs=1, verbose=3)\n",
    "grid_search = GridSearchCV(boosted_clf, param_grid, scoring='accuracy', cv=3, n_jobs=1, verbose=10)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar las predicciones en el conjunto de validación\n",
    "y_pred_boosted = grid_search.predict(X_val)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(classification_report(y_val, y_pred_boosted, target_names=[\"galaxy\", \"star\", \"qso\"]))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "ConfusionMatrixDisplay.from_estimator(grid_search.best_estimator_, X_val, y_val, display_labels=[\"galaxy\", \"star\", \"qso\"], cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
